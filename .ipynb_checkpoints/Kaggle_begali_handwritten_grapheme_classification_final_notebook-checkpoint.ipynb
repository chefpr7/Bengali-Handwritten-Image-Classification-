{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/chefpr7/Bengali-Handwritten-Grapheme-Classification-/blob/master/Kaggle_begali_handwritten_grapheme_classification_final_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7BF2Lo-ZAu-_"
   },
   "source": [
    "#KAGGLE reqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": ""
      }
     }
    },
    "colab_type": "code",
    "id": "Xoh1mcRZRmo7",
    "outputId": "04d5437b-553f-4aa9-82a4-6a5665e1a867"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "     <input type=\"file\" id=\"files-f5f9915a-523a-4325-88ba-9fbf644f6019\" name=\"files[]\" multiple disabled />\n",
       "     <output id=\"result-f5f9915a-523a-4325-88ba-9fbf644f6019\">\n",
       "      Upload widget is only available when the cell has been executed in the\n",
       "      current browser session. Please rerun this cell to enable.\n",
       "      </output>\n",
       "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving kaggle.json to kaggle.json\n",
      "Requirement already up-to-date: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.6)\n",
      "Requirement already satisfied, skipping upgrade: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2019.11.28)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
      "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.28.1)\n",
      "Requirement already satisfied, skipping upgrade: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n"
     ]
    }
   ],
   "source": [
    "# from google.colab import files\n",
    "# files.upload()  #upload kaggle.json file\n",
    "# !pip install -q kaggle\n",
    "# !pip install --upgrade kaggle\n",
    "# !mkdir -p ~/.kaggle\n",
    "# !cp kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "-C1BG6xO2RKD",
    "outputId": "1a46f672-d365-4a8e-f561-24a4a5f5e3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading resnet50ori.zip to /content\n",
      " 92% 225M/245M [00:06<00:00, 26.6MB/s]\n",
      "100% 245M/245M [00:06<00:00, 41.9MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d chefpr7/resnet50ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hRQxJM-BUTVh"
   },
   "outputs": [],
   "source": [
    "!mv '/content/drive/My Drive/resnet50bengai.pth' '/content/drive/My Drive/resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "zMTycbNESzsZ",
    "outputId": "cc4f2b6f-a2bc-49e1-9746-991ad987330c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data package template written to: /content/drive/My Drive/resnet50/dataset-metadata.json\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets init -p /content/drive/My\\ Drive/resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 171
    },
    "colab_type": "code",
    "id": "Nqn0K-ZwVSLM",
    "outputId": "8f815cb9-b523-48dd-ed80-988745c71b96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting upload for file resnet50bengai.pth\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
      "100% 183M/183M [00:06<00:00, 30.3MB/s]\n",
      "Upload successful: resnet50bengai.pth (183MB)\n",
      "Starting upload for file resnet50NEW.pth\n",
      "100% 126M/126M [00:03<00:00, 37.0MB/s]\n",
      "Upload successful: resnet50NEW.pth (126MB)\n",
      "Your private Dataset is being created. Please check progress at https://www.kaggle.com/chefpr7/effnb3\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets create -p /content/drive/My\\ Drive/resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "colab_type": "code",
    "id": "U8cWF0PYuQLX",
    "outputId": "39b15e92-1bc2-46d8-fb1e-f8380d011201"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pretrainedmodels\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/84/0e/be6a0e58447ac16c938799d49bfb5fb7a80ac35e137547fc6cee2c08c4cf/pretrainedmodels-0.7.4.tar.gz (58kB)\n",
      "\r",
      "\u001b[K     |█████▋                          | 10kB 22.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████▏                    | 20kB 29.8MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████▊               | 30kB 29.1MB/s eta 0:00:01\r",
      "\u001b[K     |██████████████████████▎         | 40kB 12.5MB/s eta 0:00:01\r",
      "\u001b[K     |███████████████████████████▉    | 51kB 12.0MB/s eta 0:00:01\r",
      "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
      "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (1.4.0)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (0.5.0)\n",
      "Collecting munch\n",
      "  Downloading https://files.pythonhosted.org/packages/cc/ab/85d8da5c9a45e072301beb37ad7f833cd344e04c817d97e0cc75681d248f/munch-2.5.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pretrainedmodels) (4.28.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.12.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (6.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->pretrainedmodels) (1.17.5)\n",
      "Building wheels for collected packages: pretrainedmodels\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-cp36-none-any.whl size=60962 sha256=f51878815931495ecf827aa2ec46a4cc4d443533f4261b22b676fd0fe71e38ab\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/df/63/62583c096289713f22db605aa2334de5b591d59861a02c2ecd\n",
      "Successfully built pretrainedmodels\n",
      "Installing collected packages: munch, pretrainedmodels\n",
      "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
     ]
    }
   ],
   "source": [
    "!pip install pretrainedmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KBh15v22A8Dn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y4T0HLeEA3Ys"
   },
   "source": [
    "#mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "4n5ocrdRA3Ci",
    "outputId": "e01f7a01-1b92-491c-f6ce-7385f3cf17af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-03-18 14:21:23--  https://he-s3.s3.amazonaws.com/media/hackathon/hackerearth-deep-learning-challenge-auto-tag-images-gala/auto-tag-images-of-the-gala-9e47fb31/9d34462453e311ea.zip?Signature=p9H6GHy%2B%2BZ%2Bzhfz4YWZVUwwDgRo%3D\n",
      "Resolving he-s3.s3.amazonaws.com (he-s3.s3.amazonaws.com)... 52.219.32.144\n",
      "Connecting to he-s3.s3.amazonaws.com (he-s3.s3.amazonaws.com)|52.219.32.144|:443... connected.\n",
      "HTTP request sent, awaiting response... 403 Forbidden\n",
      "2020-03-18 14:21:23 ERROR 403: Forbidden.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "2Vwkwe4EuRut",
    "outputId": "4ffc252a-0767-4fb9-92a2-b26ea864aa3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "joDDcIdgwMvt"
   },
   "outputs": [],
   "source": [
    "!unzip -qq '/content/drive/My Drive/bengali.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 134
    },
    "colab_type": "code",
    "id": "Iz9yB_po3PbK",
    "outputId": "4824ce6d-beb7-410a-bb94-200c64d5c564"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KaggleBengaliAIHandwrittenGraphemeClassification'...\n",
      "remote: Enumerating objects: 15, done.\u001b[K\n",
      "remote: Counting objects:   6% (1/15)\u001b[K\r",
      "remote: Counting objects:  13% (2/15)\u001b[K\r",
      "remote: Counting objects:  20% (3/15)\u001b[K\r",
      "remote: Counting objects:  26% (4/15)\u001b[K\r",
      "remote: Counting objects:  33% (5/15)\u001b[K\r",
      "remote: Counting objects:  40% (6/15)\u001b[K\r",
      "remote: Counting objects:  46% (7/15)\u001b[K\r",
      "remote: Counting objects:  53% (8/15)\u001b[K\r",
      "remote: Counting objects:  60% (9/15)\u001b[K\r",
      "remote: Counting objects:  66% (10/15)\u001b[K\r",
      "remote: Counting objects:  73% (11/15)\u001b[K\r",
      "remote: Counting objects:  80% (12/15)\u001b[K\r",
      "remote: Counting objects:  86% (13/15)\u001b[K\r",
      "remote: Counting objects:  93% (14/15)\u001b[K\r",
      "remote: Counting objects: 100% (15/15)\u001b[K\r",
      "remote: Counting objects: 100% (15/15), done.\u001b[K\n",
      "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
      "remote: Total 32 (delta 4), reused 14 (delta 4), pack-reused 17\u001b[K\n",
      "Unpacking objects: 100% (32/32), done.\n",
      "Checking out files: 100% (14/14), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/RobinSmits/KaggleBengaliAIHandwrittenGraphemeClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "60tHZY8Yj38o",
    "outputId": "a9d9edb0-f7a0-4107-8d43-4e4008db08e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/ildoonet/cutmix\n",
      "  Cloning https://github.com/ildoonet/cutmix to /tmp/pip-req-build-acv8rp99\n",
      "  Running command git clone -q https://github.com/ildoonet/cutmix /tmp/pip-req-build-acv8rp99\n",
      "Building wheels for collected packages: cutmix\n",
      "  Building wheel for cutmix (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for cutmix: filename=cutmix-0.1-cp36-none-any.whl size=3602 sha256=5a9f4f4dd9c6eb3116681345e021b09334002eb784efde27fc46a706b5af141d\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-amp3y332/wheels/8a/40/20/615302921d0fef73e55b17b5dd57169d4879dfe6dd7ad8ff50\n",
      "Successfully built cutmix\n",
      "Installing collected packages: cutmix\n",
      "Successfully installed cutmix-0.1\n"
     ]
    }
   ],
   "source": [
    "#For using cutmix \n",
    "! pip install git+https://github.com/ildoonet/cutmix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "colab_type": "code",
    "id": "dB3W7a1QCZBz",
    "outputId": "4e9972b6-aa6e-4d2c-c22b-c41df808ba7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting efficientnet_pytorch\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/cb/0309a6e3d404862ae4bc017f89645cf150ac94c14c88ef81d215c8e52925/efficientnet_pytorch-0.6.3.tar.gz\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from efficientnet_pytorch) (1.4.0)\n",
      "Building wheels for collected packages: efficientnet-pytorch\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.6.3-cp36-none-any.whl size=12422 sha256=5f2d8ea78f57076d7408ff7b4ae4564e960199cf0d9bc9ac99ed0d4cf29fae45\n",
      "  Stored in directory: /root/.cache/pip/wheels/42/1e/a9/2a578ba9ad04e776e80bf0f70d8a7f4c29ec0718b92d8f6ccd\n",
      "Successfully built efficientnet-pytorch\n",
      "Installing collected packages: efficientnet-pytorch\n",
      "Successfully installed efficientnet-pytorch-0.6.3\n"
     ]
    }
   ],
   "source": [
    "#for using efficientnet models in pytorch \n",
    "!pip install efficientnet_pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "61vDDhQKuKGV"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-efbe1aca5974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import pdb\n",
    "import time\n",
    "import copy\n",
    "import warnings\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import DataLoader, Dataset, sampler\n",
    "from matplotlib import pyplot as plt\n",
    "from albumentations import (HorizontalFlip,VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise,RandomRotate90,Transpose,RandomBrightnessContrast,RandomCrop)\n",
    "from albumentations.pytorch import ToTensor\n",
    "import albumentations as albu\n",
    "import matplotlib.image as mpi\n",
    "#import segmentation_models_pytorch as smp\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import recall_score\n",
    "import gc\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "seed = 69\n",
    "random.seed(seed)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "#from cutmix.cutmix import CutMix                                     #INCLUDE THIS FOR USING CUTMIX AUGMENTATION IN PYTORCH \n",
    "#from cutmix.utils import CutMixCrossEntropyLoss                      #INCLUDE THIS FOR USING CUTMIX AUGMENTATION IN PYTORCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JbuPUfCrNBn6"
   },
   "source": [
    "##PREPARING DATA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PZpzhgiEuKGa"
   },
   "outputs": [],
   "source": [
    "datadir = Path('bengali_ai')\n",
    "featherdir = Path('bengaliaifeather')\n",
    "outdir = Path('.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHxtTwxiNFvf"
   },
   "source": [
    "CONVERTING IMAGES FILES FROM FEATHER FORMAT(BINARY VECTORS) TO .JPG FILES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utm8kYZPuKGd"
   },
   "outputs": [],
   "source": [
    "def prepare_image(datadir, featherdir, data_type='train',\n",
    "                  submission=False, indices=[0, 1, 2, 3]):\n",
    "    assert data_type in ['train', 'test']\n",
    "    if submission:\n",
    "        image_df_list = [pd.read_parquet(datadir / f'{data_type}_image_data_{i}.parquet')\n",
    "                         for i in indices]\n",
    "    else:\n",
    "        image_df_list = [pd.read_feather(featherdir / f'{data_type}_image_data_{i}.feather')\n",
    "                         for i in tqdm(indices)]\n",
    "\n",
    "    print('image_df_list', len(image_df_list))\n",
    "    HEIGHT = 137\n",
    "    WIDTH = 236\n",
    "    for df in tqdm(image_df_list):\n",
    "        for i in tqdm(range(len(df))):\n",
    "            images = df.iloc[i]\n",
    "            image = images.iloc[1:].values\n",
    "            name = images.iloc[0]\n",
    "            path = os.path.join(\"bengali_images\",name+\".jpg\")\n",
    "            image = image.reshape(137,236).astype(np.uint8)\n",
    "            cv2.imwrite(path,image)\n",
    "            \n",
    "           \n",
    "    #images = [df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH) for df in image_df_list]\n",
    "    del image_df_list\n",
    "    gc.collect()\n",
    "    #images = np.concatenate(images, axis=0)\n",
    "    return height\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S-eqUB_vuKGf"
   },
   "outputs": [],
   "source": [
    "debug = False\n",
    "train = pd.read_csv(datadir/'train.csv')\n",
    "train_labels = train[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].values\n",
    "indices = [0] if debug else [0, 1, 2, 3]\n",
    "train_images = prepare_image(\n",
    "    datadir, featherdir, data_type='train', submission=False, indices=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l2h99KZkuKGh"
   },
   "outputs": [],
   "source": [
    "model = EfficientNet.from_name('efficientnet-b0')\n",
    "in_features = model._fc.in_features\n",
    "model._fc = nn.Linear(in_features,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xoxblp7QuKGk"
   },
   "outputs": [],
   "source": [
    "model2 = EfficientNet.from_name('efficientnet-b0')\n",
    "in_features = model2._fc.in_features\n",
    "model2._fc = nn.Linear(in_features,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WRnS44oUuKGn"
   },
   "outputs": [],
   "source": [
    "model3 = EfficientNet.from_name('efficientnet-b3')\n",
    "in_features = model3._fc.in_features\n",
    "model3._fc = nn.Linear(in_features,168)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119,
     "referenced_widgets": [
      "19899295f6074d3c8ba067f4c6bb60f0",
      "ba6c3b483d1c4bba8af837cef74dc5ff",
      "771e78a5f4ad48a8a0e50dfbe925e957",
      "560b0b15a9ac4734acdca1bfa70177be",
      "357d8761d49c410a9e6a6ed208e2482f",
      "d54785b18cca4c66b314571d204989a7",
      "00dec352d48440d098fdc3ded320f994",
      "e2a621062a67483798e3aa7d7f8a12e8"
     ]
    },
    "colab_type": "code",
    "id": "k1DQzSemuKGq",
    "outputId": "9b88158c-059a-43fa-af5c-f87b7aade55e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/lukemelas/EfficientNet-PyTorch/releases/download/1.0/efficientnet-b3-5fb5a3c3.pth\" to /root/.cache/torch/checkpoints/efficientnet-b3-5fb5a3c3.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19899295f6074d3c8ba067f4c6bb60f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49388949), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_pretrained('efficientnet-b3',num_classes=186)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 82,
     "referenced_widgets": [
      "c6f261645b99433d888c9f04fc2db8f2",
      "40f144d1a5da4a08ab1e889d2965e185",
      "65949bb21cf94e64842cf943a7d036ff",
      "b5b4ad77b64c46edb351fead556c8d9c",
      "67cf2dcad1bf4bb39b0b9c9c4f284098",
      "8852ab0cb1f744509fcd7d376e249fe6",
      "9bd4d653009f4ea3959566fa519e01a6",
      "2b137eb27b4b495caf8e973be086bb21"
     ]
    },
    "colab_type": "code",
    "id": "wV_icnOLws92",
    "outputId": "850a7995-567f-4238-e907-1b19e33e1027"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/checkpoints/resnet50-19c8e357.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f261645b99433d888c9f04fc2db8f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=102502400), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pretrainedmodels\n",
    "model_name = 'resnet50' # could be fbresnet152 or inceptionresnetv2\n",
    "model = pretrainedmodels.__dict__[model_name](num_classes=1000, pretrained='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JPA7CtJTuKGt"
   },
   "outputs": [],
   "source": [
    "in_features = model.last_linear.in_features\n",
    "model.last_linear = nn.Linear(in_features,186)\n",
    "#model._fc.requires_grad = False\n",
    "#model._fc.bias.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MZo6pM_quKGw"
   },
   "outputs": [],
   "source": [
    "ckpt_path = \"consonant_modelx.pth\"\n",
    "ckpt_path2 = \"vowel_diactric.pth\"\n",
    "ckpt_path3 = \"final_grapheme.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "#model = smp.Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\n",
    "model.to(device)\n",
    "model2.to(device)\n",
    "model3.to(device)\n",
    "#model.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "state2 = torch.load(ckpt_path2, map_location=lambda storage, loc: storage)\n",
    "state3 = torch.load(ckpt_path3, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])\n",
    "model2.load_state_dict(state2[\"state_dict\"])\n",
    "model3.load_state_dict(state3[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SyZbumUf4N37"
   },
   "outputs": [],
   "source": [
    "import PIL\n",
    "def threshold_image(img):\n",
    "    '''\n",
    "    Helper function for thresholding the images\n",
    "    '''\n",
    "    gray = PIL.Image.fromarray(np.uint8(img), 'L')\n",
    "    ret,th = cv.threshold(np.array(gray),0,255,cv.THRESH_BINARY+cv.THRESH_OTSU)\n",
    "    return th\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 263
    },
    "colab_type": "code",
    "id": "ANqbhI265otP",
    "outputId": "5830aabf-3924-4e69-ea92-5bee76f522d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f082de03a90>"
      ]
     },
     "execution_count": 26,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAADlCAYAAACoGbcCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "img=cv2.imread( os.path.join('bengali_images/',df[\"image_id\"].iloc[4]+'.jpg'),0)\n",
    "_,img = cv2.threshold(np.array(img),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "plt.imshow(img,cmap='gray')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HGokv2S4Nmuh"
   },
   "source": [
    "##DATALOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Y4VhCTmuKGy"
   },
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    def __init__(self, df, data_folder, mean, std, phase):\n",
    "        self.df = df\n",
    "        self.root = data_folder\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.phase = phase\n",
    "        self.transforms = get_transforms(phase, mean, std)\n",
    "        self.transforms2 = get_transforms2(mean, std)\n",
    "        self.fnames = self.df.index\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_id = self.df[\"image_id\"].iloc[idx]\n",
    "        image_path = os.path.join(self.root,  image_id+'.jpg')\n",
    "        img = cv2.imread(image_path,0)\n",
    "        #print(img.shape)\n",
    "        _ ,img = cv2.threshold(np.array(img),0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "        \n",
    "        img = crop_char_image3(255-img)\n",
    "        #print(img.shape)\n",
    "        #img = img.reshape(137,236,1)\n",
    "        img = img.reshape(img.shape[0],img.shape[1],1)\n",
    "        img = np.concatenate([img,img,img],axis=2)\n",
    "    \n",
    "        label = np.asarray(self.df.iloc[idx].iloc[1:]).astype(np.uint8)\n",
    "        augmented = self.transforms(image=img)\n",
    "        imgtf1 = augmented['image']\n",
    "        #aug = self.transforms2(image = img)\n",
    "        #imgtf2 = aug[\"image\"]\n",
    "        #imag2 = imag2.reshape(imag2.shape[0],imag2.shape[1],1)\n",
    "        #imag2 = np.concatenate([imag2,imag2,imag2],axis=2)\n",
    "        #aug = self.transforms(image=imag2)\n",
    "        #imagtf1 = aug['image']\n",
    "        #aug = self.transforms2(image = imag2)\n",
    "        #imagtf2 = aug[\"image\"]\n",
    "        return imgtf1,label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "\n",
    "\n",
    "def get_transforms(phase, mean, std):\n",
    "    list_transforms = []\n",
    "    if phase == 'train':\n",
    "        list_transforms.extend(\n",
    "            [GaussNoise(p=0.2),\n",
    "                   RandomBrightnessContrast(p=0.5),\n",
    "                   ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.1, rotate_limit=10, interpolation=2, border_mode=1, p=1),\n",
    "                   ]\n",
    "        )\n",
    "    list_transforms.extend(\n",
    "        [ \n",
    "            Resize(64,64,interpolation = 2),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "def get_transforms2( mean, std):\n",
    "    list_transforms = []\n",
    "    list_transforms.extend(\n",
    "        [ \n",
    "            \n",
    "            Resize(224,224,interpolation = 2),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms\n",
    "def crop_char_image3(image, threshold=80):\n",
    "    assert image.ndim == 2\n",
    "    is_black = image > threshold\n",
    "\n",
    "    is_black_vertical = np.sum(is_black, axis=0) > 0\n",
    "    is_black_horizontal = np.sum(is_black, axis=1) > 0\n",
    "    left = np.argmax(is_black_horizontal)\n",
    "    right = np.argmax(is_black_horizontal[::-1])\n",
    "    top = np.argmax(is_black_vertical)\n",
    "    bottom = np.argmax(is_black_vertical[::-1])\n",
    "    height, width = image.shape\n",
    "    cropped_image = image[left:height - right, top:width - bottom]\n",
    "    return cropped_image\n",
    "\n",
    "def provider(\n",
    "    data_folder,\n",
    "    df_path,\n",
    "    phase,\n",
    "    mean=None,\n",
    "    std=None,\n",
    "    batch_size=8,\n",
    "    num_workers=0,\n",
    "):\n",
    "    '''Returns dataloader for the model training'''\n",
    "    data = pd.read_csv(df_path)\n",
    "\n",
    "    #label = data['grapheme_root']\n",
    "    label3 = data['consonant_diacritic']\n",
    "    label2 = data['vowel_diacritic']\n",
    "    label = data['grapheme_root']\n",
    "    data2 = pd.get_dummies(label)\n",
    "    data3 = pd.get_dummies(label2)\n",
    "    data4 =  pd.get_dummies(label3)\n",
    "    dict={}\n",
    "    for i in range(168):\n",
    "        dict[(i)] = i+1\n",
    "    data2.rename(columns=dict,inplace=True)    \n",
    "    dict2 = {}\n",
    "    for i in range(11):\n",
    "        dict2[(i)] = i+169\n",
    "    data3.rename(columns=dict2,inplace=True)    \n",
    "    dict3= {}\n",
    "    for i in range(7):\n",
    "        dict3[(i)] = i+180\n",
    "    data4.rename(columns=dict3,inplace=True)\n",
    "    \n",
    "    data=data.drop(columns=['grapheme_root','vowel_diacritic','consonant_diacritic','grapheme'])\n",
    "    data=pd.concat([data,data2,data3,data4],axis=1)\n",
    "    train_df, val_df = train_test_split(data, test_size=0.001,stratify=label)\n",
    "    df = train_df if phase == \"train\" else val_df\n",
    "    image_dataset = Dataset(df, data_folder, mean, std, phase)\n",
    "    \n",
    "    #class_sample_counts=np.unique(label, return_counts=True)[1]\n",
    "   # weights = (1 / torch.Tensor(class_prob))\n",
    "   # weighted_sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_labels))\n",
    "    #train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, sampler=weighted_sampler)\n",
    "    \n",
    "    #dataset = CutMix(image_dataset, num_class=186, beta=1.0, prob=0.5, num_mix=2)\n",
    "    \n",
    "    dataloader = DataLoader(\n",
    "        #dataset,\n",
    "        image_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=False,\n",
    "        shuffle=True,   \n",
    "    )\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZhtO7BUxN-S2"
   },
   "source": [
    "##DEFINING METRICS AND HELPER FUNCTIONS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MyK_qqNzuKG1"
   },
   "outputs": [],
   "source": [
    "bs = 16\n",
    "def predict(X, threshold):\n",
    "    '''X is sigmoid output of the model'''\n",
    "    X_p = np.copy(X)\n",
    "    preds = (X_p > threshold).astype('uint8')\n",
    "    return preds\n",
    "\n",
    "def metric(probs, t, threshold=0.5, reduction='none'):\n",
    "    '''Calculates dice of positive and negative images seperately'''\n",
    "    '''probability and truth must be torch tensors'''\n",
    "    batch_size = len(t)\n",
    "    with torch.no_grad():\n",
    "        #print(probability.shape,probs2.shape,probs3.shape,truth.shape)\n",
    "        #probability = probability.view(batch_size, -1)\n",
    "        #truth = truth.view(batch_size, -1)\n",
    "        t = (t ).float().cpu()\n",
    "        pt = probs[:,:168].argmax(dim=1)\n",
    "        tt = t[:,:168].argmax(dim=1)\n",
    "        pt2 = probs[:,168:179].argmax(dim=1)\n",
    "        tt2 = t[:,168:179].argmax(dim=1)\n",
    "        pt3 = probs[:,179:].argmax(dim=1)\n",
    "        tt3 = t[:,179:].argmax(dim=1)\n",
    "        csum = (pt==tt).sum().float()\n",
    "        acc  = csum/bs\n",
    "        rec_sc=recall_score(tt,pt,average = 'macro')\n",
    "        csum = (pt2==tt2).sum().float()\n",
    "        acc2 = csum/bs\n",
    "        rec_sc2 = recall_score(tt2,pt2,average = 'macro')\n",
    "        csum = (pt3==tt3).sum().float()\n",
    "        acc3 = csum/bs\n",
    "        rec_sc3 = recall_score(tt3,pt3,average = 'macro')\n",
    "\n",
    "        #dice_pos = (2 * (p*t).sum(-1)+1)/(((p+t).sum(-1))+1)\n",
    "        \n",
    "        #p_neg = (p == 0).float()\n",
    "        #t_neg = (t == 0).float()\n",
    "        #dice_neg = (2 * (p_neg*t_neg).sum(-1)+1)/(((p_neg+t_neg).sum(-1))+1)\n",
    "\n",
    "        #dice = torch.cat([dice_pos, dice_neg])\n",
    "\n",
    "        #dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n",
    "        #dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n",
    "        #dice = dice.mean().item()\n",
    "\n",
    "\n",
    "    return acc,rec_sc,acc2,rec_sc2,acc3,rec_sc3\n",
    "\n",
    "class Meter:\n",
    "    '''A meter to keep track of iou and dice scores throughout an epoch'''\n",
    "    def __init__(self, phase, epoch):\n",
    "        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n",
    "        self.phase = phase\n",
    "        self.base_dice_scores = []\n",
    "        self.rec_sc = []\n",
    "        self.base_dice_scores2 = []\n",
    "        self.rec_sc2 = []\n",
    "        self.base_dice_scores3 = []\n",
    "        self.rec_sc3 = []\n",
    "        #self.dice_neg_scores = []\n",
    "        #self.dice_pos_scores = []\n",
    "        #self.iou_scores = []\n",
    "\n",
    "    def update(self, targets, outputs):\n",
    "        #print(outputs.shape)\n",
    "        #probs = torch.softmax(outputs[:,:168],dim=1)\n",
    "        #probs2 = torch.softmax(outputs[:,168:179],dim=1)\n",
    "        #probs3 = torch.softmax(outputs[:,179:],dim=1)\n",
    "        #print(probs,probs.shape)\n",
    "        dice,rec,dice2,rec2,dice3,rec3 = metric(outputs, targets, self.base_threshold)\n",
    "\n",
    "        self.base_dice_scores.append(dice)\n",
    "        self.rec_sc.append(rec)\n",
    "       \n",
    "        self.base_dice_scores2.append(dice2)\n",
    "        self.rec_sc2.append(rec2)\n",
    "        \n",
    "        self.base_dice_scores3.append(dice3)\n",
    "        self.rec_sc3.append(rec3)\n",
    "        #self.dice_pos_scores.append(dice_pos)\n",
    "        #self.dice_neg_scores.append(dice_neg)\n",
    "        #preds = predict(probs, self.base_threshold)\n",
    "        #iou = compute_iou_batch(preds, targets, classes=[1])\n",
    "        #self.iou_scores.append(iou)\n",
    "\n",
    "    def get_metrics(self):\n",
    "        dice = np.mean(self.base_dice_scores)\n",
    "        rec = np.mean(self.rec_sc)\n",
    "        dice2 = np.mean(self.base_dice_scores2)\n",
    "        rec2 = np.mean(self.rec_sc2)\n",
    "        dice3 = np.mean(self.base_dice_scores3)\n",
    "        rec3 = np.mean(self.rec_sc3)\n",
    "        #dice_neg = np.mean(self.dice_neg_scores)\n",
    "        #dice_pos = np.mean(self.dice_pos_scores)\n",
    "        #dices = [dice, dice_neg, dice_pos]\n",
    "        #iou = np.nanmean(self.iou_scores)\n",
    "        return dice,rec,dice2,rec2,dice3,rec3\n",
    "\n",
    "def epoch_log(phase, epoch, epoch_loss, meter, start):\n",
    "    '''logging the metrics at the end of an epoch'''\n",
    "    dice,rec,dice2,rec2,dice3,rec3 = meter.get_metrics()\n",
    "    print(\"Loss: %0.4f  | acc: %0.4f  | rec: %0.4f |acc2: %0.4f  | rec2: %0.4f| acc3: %0.4f | rec3: %0.4f\" % (epoch_loss, dice, rec,dice2,rec2,dice3,rec3 ))\n",
    "    return dice,rec,dice2,rec2,dice3,rec3\n",
    "    #dice, dice_neg, dice_pos = dices\n",
    "    #print(\"Loss: %0.4f  | acc: %0.4f  | rec: %0.4f \" % (epoch_loss, dice, rec ))\n",
    "    #return dice,rec\n",
    "\n",
    "def compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n",
    "    '''computes iou for one ground truth mask and predicted mask'''\n",
    "    pred[label == ignore_index] = 0\n",
    "    ious = []\n",
    "    for c in classes:\n",
    "        label_c = label == c\n",
    "        if only_present and np.sum(label_c) == 0:\n",
    "            ious.append(np.nan)\n",
    "            continue\n",
    "        pred_c = pred == c\n",
    "        intersection = np.logical_and(pred_c, label_c).sum()\n",
    "        union = np.logical_or(pred_c, label_c).sum()\n",
    "        if union != 0:\n",
    "            ious.append(intersection / union)\n",
    "    return ious if ious else [1]\n",
    "\n",
    "def compute_iou_batch(outputs, labels, classes=None):\n",
    "    '''computes mean iou for a batch of ground truth masks and predicted masks'''\n",
    "    ious = []\n",
    "    preds = np.copy(outputs) # copy is imp\n",
    "    labels = np.array(labels) # tensor to np\n",
    "    for pred, label in zip(preds, labels):\n",
    "        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n",
    "    iou = np.nanmean(ious)\n",
    "    return iou\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vnz3Ja26OMrl"
   },
   "source": [
    "## TRYING A CUSTOM FUNCTION TO SUPPLY CLASS WEIGHTS\n",
    "$weight (class x)$ = $e^(-freq[class i]/freq[most occuring class])$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "XP0ee1jagaQ7",
    "outputId": "f2faf00c-f164-4e0f-9c05-76885e228b74"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>grapheme_root</th>\n",
       "      <th>vowel_diacritic</th>\n",
       "      <th>consonant_diacritic</th>\n",
       "      <th>grapheme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Train_0</td>\n",
       "      <td>15</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>ক্ট্রো</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Train_1</td>\n",
       "      <td>159</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>হ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Train_2</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>খ্রী</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Train_3</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>র্টি</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Train_4</td>\n",
       "      <td>71</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>থ্রো</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_id  grapheme_root  vowel_diacritic  consonant_diacritic grapheme\n",
       "0  Train_0             15                9                    5   ক্ট্রো\n",
       "1  Train_1            159                0                    0        হ\n",
       "2  Train_2             22                3                    5     খ্রী\n",
       "3  Train_3             53                2                    2     র্টি\n",
       "4  Train_4             71                9                    5     থ্রো"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "WhR5fYA9gl5T",
    "outputId": "293aba3d-3735-4845-8b36-e0da1deab323"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"vowel_diacritic\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lFqSEOG2csBk"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/content/train.csv')\n",
    "df.head()\n",
    "x = df[\"grapheme_root\"].value_counts()\n",
    "gr = [0]*168\n",
    "for i in range(len(x)):\n",
    "    gr[x.index[i]]=x.values[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPbug2U3fBd5"
   },
   "outputs": [],
   "source": [
    "for i in range(len(gr)):\n",
    "    gr[i]=np.exp(-gr[i]/max(gr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-sghbK46hD-d"
   },
   "outputs": [],
   "source": [
    "#weights = []\n",
    "#weights.append(gr)\n",
    "#weights.append(vd)\n",
    "#weights.append(cd)\n",
    "#len(weights)\n",
    "gr=torch.Tensor(gr)\n",
    "vd=torch.Tensor(vd)\n",
    "cd=torch.Tensor(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "K9Sd-1bylZVA",
    "outputId": "190ffe27-617d-4534-a6cd-1cbcb18d40d3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9746979848841162,\n",
       " 0.9750378969939706,\n",
       " 0.9429408314103613,\n",
       " 0.9460694194464112,\n",
       " 0.9439276872401755,\n",
       " 0.9699516388813939,\n",
       " 0.9477202119426896,\n",
       " 0.9736789593785679,\n",
       " 0.9730002009819598,\n",
       " 0.9255141502886863,\n",
       " 0.9738487229487731,\n",
       " 0.9740185161177177,\n",
       " 0.974867926124185,\n",
       " 0.388714808443331,\n",
       " 0.870425885213277,\n",
       " 0.8279458449540238,\n",
       " 0.8488461974472313,\n",
       " 0.8757532982010876,\n",
       " 0.7522450332877768,\n",
       " 0.9526898923094402,\n",
       " 0.9431052357044982,\n",
       " 0.8485502775626753,\n",
       " 0.5967760335728777,\n",
       " 0.40752056665067915,\n",
       " 0.9431052357044982,\n",
       " 0.821619092743351,\n",
       " 0.9706282706215826,\n",
       " 0.9482160111529087,\n",
       " 0.8760587047535993,\n",
       " 0.6159076173894815,\n",
       " 0.9266443026214365,\n",
       " 0.8746852134677378,\n",
       " 0.821619092743351,\n",
       " 0.9765689690119786,\n",
       " 0.9530221294088843,\n",
       " 0.920365267081043,\n",
       " 0.8365059732194667,\n",
       " 0.951527974299331,\n",
       " 0.5572573965639479,\n",
       " 0.8980170284175842,\n",
       " 0.8763642178123182,\n",
       " 0.9482160111529087,\n",
       " 0.7109319801497667,\n",
       " 0.5310786307022247,\n",
       " 0.8317072559321733,\n",
       " 0.9752078974986387,\n",
       " 0.90382839955342,\n",
       " 0.9242242353055946,\n",
       " 0.786715634762185,\n",
       " 0.9455747426370589,\n",
       " 0.8792719109736896,\n",
       " 0.9447508560092037,\n",
       " 0.8495864487280153,\n",
       " 0.5255523683345171,\n",
       " 0.9019395216636579,\n",
       " 0.7461064241097882,\n",
       " 0.625865838177159,\n",
       " 0.89551558984667,\n",
       " 0.7992961829102351,\n",
       " 0.6651282144159246,\n",
       " 0.9284230451747876,\n",
       " 0.9046165990321835,\n",
       " 0.8595683235339298,\n",
       " 0.9743581912724686,\n",
       " 0.376968839966319,\n",
       " 0.7882257768663121,\n",
       " 0.8719446876291901,\n",
       " 0.9205257352642441,\n",
       " 0.895827888218343,\n",
       " 0.8763642178123182,\n",
       " 0.8463341642311969,\n",
       " 0.5993827212937476,\n",
       " 0.36787944117144233,\n",
       " 0.975864535458579,\n",
       " 0.7518001706097062,\n",
       " 0.8091246515215549,\n",
       " 0.6950014249034558,\n",
       " 0.8353926618001812,\n",
       " 0.9464237822721553,\n",
       " 0.5221095524576096,\n",
       " 0.9178712240315358,\n",
       " 0.524075694188411,\n",
       " 0.9466016647605466,\n",
       " 0.7660626982873333,\n",
       " 0.9171814842751406,\n",
       " 0.7740220959124544,\n",
       " 0.6746676701937494,\n",
       " 0.9689202104954587,\n",
       " 0.8669011738269324,\n",
       " 0.6474635846381643,\n",
       " 0.8888427054078896,\n",
       " 0.7488389433508096,\n",
       " 0.8107990693550049,\n",
       " 0.8896783194343766,\n",
       " 0.8328844477764068,\n",
       " 0.8722942639875216,\n",
       " 0.3962278582877947,\n",
       " 0.9135688450143804,\n",
       " 0.8888427054078896,\n",
       " 0.9175262893403567,\n",
       " 0.9192522600307863,\n",
       " 0.8158431419842413,\n",
       " 0.9738492334645805,\n",
       " 0.5218152680769814,\n",
       " 0.9703780551865892,\n",
       " 0.9720207525274753,\n",
       " 0.8683687010916363,\n",
       " 0.36787944117144233,\n",
       " 0.9646885815778243,\n",
       " 0.8133462183287541,\n",
       " 0.9251349135129595,\n",
       " 0.836049780406665,\n",
       " 0.817427782960675,\n",
       " 0.36787944117144233,\n",
       " 0.9664236252289529,\n",
       " 0.40085235442366957,\n",
       " 0.9054969204980539,\n",
       " 0.7056835704610853,\n",
       " 0.7715643861760914,\n",
       " 0.7047201800709344,\n",
       " 0.7597104914044246,\n",
       " 0.9001523458370778,\n",
       " 0.5905863959278403,\n",
       " 0.6237569214162065,\n",
       " 0.6076364582392737,\n",
       " 0.8310134577461178,\n",
       " 0.9644452766365348,\n",
       " 0.8097209686834079,\n",
       " 0.8051249941766734,\n",
       " 0.8003728514080064,\n",
       " 0.9677447783045844,\n",
       " 0.9040548827087707,\n",
       " 0.7893334021071968,\n",
       " 0.3693902375787902,\n",
       " 0.8677524368286014,\n",
       " 0.8649907810328915,\n",
       " 0.7871796970274226,\n",
       " 0.8798886380921611,\n",
       " 0.8084314576876398,\n",
       " 0.5907208799067487,\n",
       " 0.817873697091804,\n",
       " 0.671970402312655,\n",
       " 0.7843172285618483,\n",
       " 0.8705229097619054,\n",
       " 0.8699284933222149,\n",
       " 0.9303664995936423,\n",
       " 0.933549413017214,\n",
       " 0.36787944117144233,\n",
       " 0.5914697293594182,\n",
       " 0.4809009891543989,\n",
       " 0.4944256825370276,\n",
       " 0.6836071709239462,\n",
       " 0.831100484237447,\n",
       " 0.6229236614862502,\n",
       " 0.800032671648397,\n",
       " 0.7536399104626665,\n",
       " 0.7860143341211963,\n",
       " 0.9059688268500278,\n",
       " 0.9573518716933114,\n",
       " 0.36787944117144233,\n",
       " 0.7387179341755225,\n",
       " 0.821835922889092,\n",
       " 0.7457421407801692,\n",
       " 0.9011343265885244,\n",
       " 0.9017030449834045,\n",
       " 0.48650663857855164,\n",
       " 0.8239125760442625,\n",
       " 0.36787944117144233]"
      ]
     },
     "execution_count": 85,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KBditmiFk4Vx",
    "outputId": "97c0d7ae-5c6a-43cc-a022-4dead5b6c109"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3, [4, 5, 6]], [4, 5, 6]]"
      ]
     },
     "execution_count": 82,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#x = [1,2,3]\n",
    "#y = [4,5,6]\n",
    "#x.append(y)\n",
    "k=[]\n",
    "k.append(x)\n",
    "k.append(y)\n",
    "k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "o1R92Kk7O946"
   },
   "source": [
    "##TRAINER "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2I1QyxehuKG3"
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    '''This class takes care of training and validation of our model'''\n",
    "    def __init__(self, model):\n",
    "        self.num_workers = 0\n",
    "        self.batch_size = {\"train\": 16, \"val\": 16}\n",
    "        self.accumulation_steps = 1\n",
    "        self.lr = 3e-6\n",
    "        self.num_epochs = 15\n",
    "        self.best_loss = float(\"inf\")\n",
    "        self.phases = [\"train\", \"val\"]\n",
    "        self.device = torch.device(\"cuda:0\")\n",
    "        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n",
    "        self.net = model\n",
    "        #pos_wt = torch.tensor([3.0])\n",
    "        self.criterion1 = torch.nn.BCEWithLogitsLoss(weight=gr)\n",
    "        self.criterion2 = torch.nn.BCEWithLogitsLoss(weight=vd)\n",
    "        self.criterion3 = torch.nn.BCEWithLogitsLoss(weight=cd)\n",
    "        #self.criterion = CutMixCrossEntropyLoss(True)\n",
    "        #self.optimizer = optim.SGD(model.parameters(), lr=self.lr, momentum=0.09)\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n",
    "        \n",
    "        self.scheduler = ReduceLROnPlateau(self.optimizer,factor=0.33, mode=\"min\", patience=3, verbose=True)\n",
    "        self.net = self.net.to(self.device)\n",
    "        cudnn.benchmark = True\n",
    "        \n",
    "        self.dataloaders = {\n",
    "            phase: provider(\n",
    "                data_folder=data_folder,\n",
    "                df_path=train_df_path,\n",
    "                phase=phase,\n",
    "                mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225),\n",
    "                batch_size=self.batch_size[phase],\n",
    "                num_workers=self.num_workers,\n",
    "            )\n",
    "            for phase in self.phases\n",
    "        }\n",
    "        self.losses = {phase: [] for phase in self.phases}\n",
    "        self.rec_scores = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores = {phase: [] for phase in self.phases}\n",
    "        self.rec_scores2 = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores2 = {phase: [] for phase in self.phases}\n",
    "        self.rec_scores3 = {phase: [] for phase in self.phases}\n",
    "        self.dice_scores3 = {phase: [] for phase in self.phases}\n",
    "    def forward(self, images, targets):\n",
    "        images = images.to(self.device)\n",
    "        #print(\"targets =\",targets.shape)\n",
    "        #targets = targets.reshape(targets.shape[0],1)\n",
    "        masks = targets.to(self.device)\n",
    "        masks = masks.float()\n",
    "        #masks = masks.reshape(4,1)\n",
    "        outputs = self.net(images)\n",
    "        #rec_sc=recall_score(masks.argmax(dim=1).cpu().numpy(),outputs.argmax(dim=1).cpu().numpy(),average = 'macro') \n",
    "        #print(outputs.type(),masks.type())\n",
    "        #loss = self.criterion(outputs,masks)\n",
    "        loss1 = self.criterion1(outputs[:,:168],masks[:,:168])#+(1-rec_sc)\n",
    "        loss2 = self.criterion2(outputs[:,168:179],masks[:,168:179])\n",
    "        loss3 = self.criterion3(outputs[:,179:],masks[:,179:])\n",
    "        loss = 8*loss1+loss2+loss3\n",
    "        #print(loss,rec_sc)\n",
    "        #loss = self.criterion(outputs.permute(0,2,3,1), masks.permute(0,2,3,1))\n",
    "        '''  after few epochs loss = \"0.25*bce+0.75*dice\"\n",
    "        \n",
    "        d1,d2,d3 = metric(outputs, mask, threshold=0.5, reduction='none')\n",
    "        loss =  0.25*self.criterion(outputs.permute(0,2,3,1), masks.permute(0,2,3,1)) +0.75*(1-d1)\n",
    "        \n",
    "        '''\n",
    "\n",
    "        return loss, outputs\n",
    "\n",
    "    def iterate(self, epoch, phase):\n",
    "        meter = Meter(phase, epoch)\n",
    "        start = time.strftime(\"%H:%M:%S\")\n",
    "        print(f\"Starting epoch: {epoch} | phase: {phase} | ⏰: {start}\")\n",
    "        batch_size = self.batch_size[phase]\n",
    "        self.net.train(phase == \"train\")\n",
    "        dataloader = self.dataloaders[phase]\n",
    "        running_loss = 0.0\n",
    "        total_batches = len(dataloader)\n",
    "        tk0 = tqdm(dataloader, total=total_batches)\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        for itr, batch in enumerate(tk0):\n",
    "                   \n",
    "            img1, targets = batch\n",
    "            loss, outputs = self.forward(img1, targets)\n",
    "            #loss2, outputs2 = self.forward(img2, targets)\n",
    "            #loss3, outputs3 = self.forward(img3, targets)\n",
    "            #loss4, outputs4 = self.forward(img4, targets)\n",
    "            \n",
    "            #loss = (loss1+loss2+loss3+loss4)/4\n",
    "            #outputs = (outputs1+outputs2+outputs3+outputs4)/4\n",
    "            \n",
    "            loss = loss / self.accumulation_steps\n",
    "\n",
    "            if phase == \"train\":\n",
    "                loss.backward()\n",
    "                if (itr + 1 ) % self.accumulation_steps == 0:\n",
    "                    self.optimizer.step()\n",
    "                    self.optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            outputs = outputs.detach().cpu()\n",
    "            meter.update(targets, outputs)\n",
    "            tk0.set_postfix(loss=(running_loss / ((itr + 1))))\n",
    "        epoch_loss = (running_loss * self.accumulation_steps) / total_batches\n",
    "        dice,rec,dice2,rec2,dice3,rec3 = epoch_log(phase, epoch, epoch_loss, meter, start)\n",
    "        self.losses[phase].append(epoch_loss)\n",
    "        self.dice_scores[phase].append(dice)\n",
    "        self.rec_scores[phase].append(rec)\n",
    "        self.dice_scores2[phase].append(dice2)\n",
    "        self.rec_scores2[phase].append(rec2)\n",
    "        self.dice_scores3[phase].append(dice3)\n",
    "        self.rec_scores3[phase].append(rec3)\n",
    "        torch.cuda.empty_cache()\n",
    "        return epoch_loss\n",
    "    def start2(self):\n",
    "        for epoch in range(self.num_epochs):\n",
    "            \n",
    "            val_loss = self.iterate(epoch, \"val\")\n",
    "            self.scheduler.step(val_loss)\n",
    "    def start(self): \n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.iterate(epoch, \"train\")\n",
    "            state = {\n",
    "                \"epoch\": epoch,\n",
    "                \"best_loss\": self.best_loss,\n",
    "                \"state_dict\": self.net.state_dict(),\n",
    "                \"optimizer\": self.optimizer.state_dict(),\n",
    "            }\n",
    "            val_loss = self.iterate(epoch, \"val\")\n",
    "            self.scheduler.step(val_loss)\n",
    "            \n",
    "            if val_loss < self.best_loss:\n",
    "                print(\"******** New optimal found, saving state ********\")\n",
    "                state[\"best_loss\"] = self.best_loss = val_loss\n",
    "                torch.save(state, \"/content/drive/My Drive/resnet50/resnet50NEW.pth\")\n",
    "            print()\n",
    "            np.save(\"logacctrain.npy\",self.dice_scores[\"train\"])\n",
    "            np.save(\"logrectrain.npy\",self.rec_scores[\"train\"])\n",
    "            np.save(\"logaccval.npy\",self.dice_scores[\"val\"])\n",
    "            np.save(\"logrecval.npy\",self.rec_scores[\"val\"])\n",
    "            np.save(\"logacctrain2.npy\",self.dice_scores2[\"train\"])\n",
    "            np.save(\"logrectrain2.npy\",self.rec_scores2[\"train\"])\n",
    "            np.save(\"logaccval2.npy\",self.dice_scores2[\"val\"])\n",
    "            np.save(\"logrecval2.npy\",self.rec_scores2[\"val\"])\n",
    "            np.save(\"logacctrain3.npy\",self.dice_scores3[\"train\"])\n",
    "            np.save(\"logrectrain3.npy\",self.rec_scores3[\"train\"])\n",
    "            np.save(\"logaccval3.npy\",self.dice_scores3[\"val\"])\n",
    "            np.save(\"logrecval3.npy\",self.rec_scores3[\"val\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uHnzWGEduKG5"
   },
   "outputs": [],
   "source": [
    "train_df_path = 'train.csv'\n",
    "data_folder = \"bengali_images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3d3xrdouKG8"
   },
   "outputs": [],
   "source": [
    "#model = smp.Unet('resnet18', classes=1, activation=None,encoder_weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqC-MEvZuKHA"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "a87f04cc877946348866cc2609d8758c",
      "e5a09d6e145c4c8dba5b99bbeff4415e",
      "0a5389affce44d26b8a39a7df5a4eddf",
      "7d192d44e696488d80ec951cc59f2643",
      "99b664e9c51e4a6692dbb52fa18797e8",
      "44a200cec2824dc1a82ce103e08382df",
      "0bdf22a4f61f467f8c8f52d056d8c164",
      "adafe2e08c714afc8a70f5889b60816f"
     ]
    },
    "colab_type": "code",
    "id": "yHTi4ZYfuKHD",
    "outputId": "22dfb1d7-1185-41a0-aadf-2b0d060183dc",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch: 0 | phase: train | ⏰: 23:43:59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87f04cc877946348866cc2609d8758c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=12540), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_trainer = Trainer(model)\n",
    "model_trainer.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xdMUA9iZuKHF"
   },
   "outputs": [],
   "source": [
    "scores = [0.9275,0.9676,0.9632]\n",
    "np.average(scores, weights=[2,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "FKIGdsMJ4Jx-",
    "outputId": "03721f21-50a6-4bd5-bebf-5a14531ba1ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/resnet50ori.zip\n",
      "  inflating: resnet50bengai.pth      \n"
     ]
    }
   ],
   "source": [
    "!unzip /content/resnet50ori.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "IvMV1Y-VuKHH",
    "outputId": "b38a09c8-3370-4061-996f-0e58179cbf08"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt_path = \"/content/drive/My Drive/resnet50/resnet50NEW.pth\"\n",
    "device = torch.device(\"cuda\")\n",
    "#model = smp.Unet(\"resnet18\", encoder_weights=None, classes=4, activation=None)\n",
    "model.to(device)\n",
    "#model.eval()\n",
    "state = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
    "model.load_state_dict(state[\"state_dict\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fh7AHnoTuKHJ"
   },
   "outputs": [],
   "source": [
    "def get_transforms2(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)):\n",
    "    list_transforms = []\n",
    "    \n",
    "    list_transforms.extend(\n",
    "        [ \n",
    "            #HorizontalFlip(),\n",
    "            Resize(224,224,interpolation = 2),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XldWKj6uKHL"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "filenames = glob.glob('deepfake_frames/test/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdbRc_spuKHO"
   },
   "outputs": [],
   "source": [
    "len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3B6O4JfeuKHQ"
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(48, 2, figsize=(10, 100))\n",
    "axs = np.array(axs)\n",
    "axs = axs.reshape(-1)\n",
    "model.eval()\n",
    "transforms = get_transforms2()\n",
    "for i,j in enumerate(tqdm(filenames)):\n",
    "    img = mpi.imread(j)\n",
    "    augmented = transforms(image=img)\n",
    "    img2 = augmented['image']\n",
    "    img2=img2.reshape(1,3,img2.shape[1],img2.shape[2])\n",
    "\n",
    "    img2=img2.to(device)\n",
    "    prob = model(img2)\n",
    "    prob = torch.sigmoid(prob)\n",
    "    ax = axs[i]\n",
    "    ax.imshow(img)\n",
    "    ax.grid(False)\n",
    "    ax.title.set_text(str(prob.cpu()))\n",
    "    ax.xaxis.set_visible(False)\n",
    "    ax.yaxis.set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aLnH77lxuKHS"
   },
   "source": [
    "# Post Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4TuJc_fuKHT"
   },
   "outputs": [],
   "source": [
    "\n",
    "def post_process(probability, threshold, min_size):\n",
    "    '''Post processing of each predicted mask, components with lesser number of pixels\n",
    "    than `min_size` are ignored'''\n",
    "    mask = cv2.threshold(probability, threshold, 1, cv2.THRESH_BINARY)[1]\n",
    "    num_component, component = cv2.connectedComponents(mask.astype(np.uint8))\n",
    "    predictions = np.zeros((256, 320), np.int32)\n",
    "    num = 0\n",
    "    for c in range(1, num_component):\n",
    "        p = (component == c)\n",
    "        if p.sum() > min_size:\n",
    "            predictions[p] = 1\n",
    "            num += 1\n",
    "    return predictions, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nYLGzQYRuKHU"
   },
   "outputs": [],
   "source": [
    "def get_transforms2(mean=(0.485, 0.456, 0.406),\n",
    "                std=(0.229, 0.224, 0.225)):\n",
    "    list_transforms = []\n",
    "    list_transforms.extend(\n",
    "        [   Resize(256,320,interpolation=2),\n",
    "            Normalize(mean=mean, std=std, p=1),\n",
    "            ToTensor(),\n",
    "        ]\n",
    "    )\n",
    "    list_trfms = Compose(list_transforms)\n",
    "    return list_trfms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KoaxGCbtuKHX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_transforms2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-ffb21b4cfbc8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtransforms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_transforms2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmpi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'file_name.jpg'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0maugmented\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maugmented\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_transforms2' is not defined"
     ]
    }
   ],
   "source": [
    "transforms = get_transforms2()\n",
    "\n",
    "img = mpi.imread('file_name.jpg')\n",
    "augmented = transforms(image=img)\n",
    "img = augmented['image']\n",
    "img2=img.reshape(1,3,img.shape[1],img.shape[2])\n",
    "prob = model.predict(img2)\n",
    "prob = torch.sigmoid(prob)\n",
    "prob = prob[0,0].numpy()\n",
    "output,num  = post_process(prob,0.5,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "aLnH77lxuKHS"
   ],
   "include_colab_link": true,
   "name": "Kaggle-begali-handwritten-grapheme-classification-final-notebook.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00dec352d48440d098fdc3ded320f994": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0a5389affce44d26b8a39a7df5a4eddf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44a200cec2824dc1a82ce103e08382df",
      "max": 12540,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99b664e9c51e4a6692dbb52fa18797e8",
      "value": 128
     }
    },
    "0bdf22a4f61f467f8c8f52d056d8c164": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19899295f6074d3c8ba067f4c6bb60f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_771e78a5f4ad48a8a0e50dfbe925e957",
       "IPY_MODEL_560b0b15a9ac4734acdca1bfa70177be"
      ],
      "layout": "IPY_MODEL_ba6c3b483d1c4bba8af837cef74dc5ff"
     }
    },
    "2b137eb27b4b495caf8e973be086bb21": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "357d8761d49c410a9e6a6ed208e2482f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "40f144d1a5da4a08ab1e889d2965e185": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a200cec2824dc1a82ce103e08382df": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "560b0b15a9ac4734acdca1bfa70177be": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e2a621062a67483798e3aa7d7f8a12e8",
      "placeholder": "​",
      "style": "IPY_MODEL_00dec352d48440d098fdc3ded320f994",
      "value": "100% 47.1M/47.1M [00:01&lt;00:00, 29.9MB/s]"
     }
    },
    "65949bb21cf94e64842cf943a7d036ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8852ab0cb1f744509fcd7d376e249fe6",
      "max": 102502400,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67cf2dcad1bf4bb39b0b9c9c4f284098",
      "value": 102502400
     }
    },
    "67cf2dcad1bf4bb39b0b9c9c4f284098": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "771e78a5f4ad48a8a0e50dfbe925e957": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d54785b18cca4c66b314571d204989a7",
      "max": 49388949,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_357d8761d49c410a9e6a6ed208e2482f",
      "value": 49388949
     }
    },
    "7d192d44e696488d80ec951cc59f2643": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_adafe2e08c714afc8a70f5889b60816f",
      "placeholder": "​",
      "style": "IPY_MODEL_0bdf22a4f61f467f8c8f52d056d8c164",
      "value": "  1% 128/12540 [00:21&lt;33:01,  6.26it/s, loss=1.72]"
     }
    },
    "8852ab0cb1f744509fcd7d376e249fe6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99b664e9c51e4a6692dbb52fa18797e8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9bd4d653009f4ea3959566fa519e01a6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a87f04cc877946348866cc2609d8758c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0a5389affce44d26b8a39a7df5a4eddf",
       "IPY_MODEL_7d192d44e696488d80ec951cc59f2643"
      ],
      "layout": "IPY_MODEL_e5a09d6e145c4c8dba5b99bbeff4415e"
     }
    },
    "adafe2e08c714afc8a70f5889b60816f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b5b4ad77b64c46edb351fead556c8d9c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b137eb27b4b495caf8e973be086bb21",
      "placeholder": "​",
      "style": "IPY_MODEL_9bd4d653009f4ea3959566fa519e01a6",
      "value": "100% 97.8M/97.8M [00:00&lt;00:00, 250MB/s]"
     }
    },
    "ba6c3b483d1c4bba8af837cef74dc5ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c6f261645b99433d888c9f04fc2db8f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_65949bb21cf94e64842cf943a7d036ff",
       "IPY_MODEL_b5b4ad77b64c46edb351fead556c8d9c"
      ],
      "layout": "IPY_MODEL_40f144d1a5da4a08ab1e889d2965e185"
     }
    },
    "d54785b18cca4c66b314571d204989a7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2a621062a67483798e3aa7d7f8a12e8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5a09d6e145c4c8dba5b99bbeff4415e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
